{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "genai.configure(api_key='AIzaSyDlTl5fVv3_dJEkKlIgnQvBl1vwPpOdyXA')\n",
    "\n",
    "llm_model = genai.GenerativeModel('gemini-1.5-pro')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_zero_shot(text):\n",
    "    prompt = f\"\"\"\n",
    "            You are an expert at distinguishing AI-generated from human-written text.\n",
    "            Read the following text carefully and classify it explicitly as either 'AI' (generated by artificial intelligence) or 'Human' (written by a real person).\n",
    "\n",
    "            Text:\n",
    "            \\\"\\\"\\\"\n",
    "            {text}\n",
    "            \\\"\\\"\\\"\n",
    "\n",
    "            Your response must strictly be either 'AI' or 'Human', with no further explanation:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    response = llm_model.generate_content(prompt)\n",
    "    print(f\"resposta: {response}\")\n",
    "    \n",
    "    classification = response.text.strip().lower()\n",
    "    \n",
    "    print(f\"classification: {classification}\")\n",
    "    \n",
    "    if 'ai' in classification:\n",
    "        return 'AI'\n",
    "    \n",
    "    elif 'human' in classification:\n",
    "        return 'Human'\n",
    "    else:\n",
    "        return 'Uncertain'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_one_shot(text):\n",
    "    prompt = f\"\"\"\n",
    "            You are an expert at distinguishing AI-generated from human-written text.\n",
    "            Read the third text carefully and classify it explicitly as either 'AI' (generated by artificial intelligence) or 'Human' (written by a real person), Use the information from the first two examples:\n",
    "            \n",
    "            Text: \"Although this technique was first thought of as a way to accurately define a standard unit of current, it turned out to be more useful in the field of quantum information. Usually, qubits are stationary, making the transfer of information between them difficult. The single electrons, carried by the SAWs, can be used as so called flying qubits, able to transport information from one place to another. To realise this a single electron source is needed, as well as a receiver between which the electron can be transported. Quantum dots (QD) are typically used for these stationary electron confinements. This potential minimum is sometimes called a SAW QD. The process, as seen in the GIF on the right, is typically as follows. First SAWs are generated with an interdigital transducer with specific dimensions between the electrodes to get the favorable wavelengths. Then from the stationary QD the electron quantum tunnels to the potential minimum, or SAW QD. The SAWs transfer some kinetic energy to the electron, driving it forward.\"\n",
    "\"\n",
    "            Classification: Human\n",
    "            \n",
    "            Text: \"Many scholars argue that the full potential of plate tectonics has yet to be realized, pointing to gaps in current models and empirical validation. With recent breakthroughs, plate tectonics is becoming increasingly relevant to modern scientific challenges, such as sustainability and artificial intelligence. Despite technical difficulties, plate tectonics continues to evolve through rigorous experimentation and continuous refinement of theories. Among the many branches of science, plate tectonics stands out for its complexity and potential to reshape our understanding of the world. Plate tectonics is a field that has witnessed dramatic transformations in recent years, with scientists exploring its implications across multiple domains. While some aspects of plate tectonics remain theoretical, its real-world applications are beginning to influence innovation and policy. The ongoing development of plate tectonics has sparked discussions not only about its scientific basis but also about its ethical and societal ramifications.\"\n",
    "\"   \n",
    "            Classification: AI\n",
    "             \n",
    "            Text:\n",
    "            \\\"\\\"\\\"\n",
    "            {text}\n",
    "            \\\"\\\"\\\"\n",
    "\n",
    "            Your response must strictly be either 'AI' or 'Human', with no further explanation:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    response = llm_model.generate_content(prompt)\n",
    "    print(f\"resposta: {response}\")\n",
    "    \n",
    "    classification = response.text.strip().lower()\n",
    "    \n",
    "    print(f\"classification: {classification}\")\n",
    "    \n",
    "    if 'ai' in classification:\n",
    "        return 'AI'\n",
    "    \n",
    "    elif 'human' in classification:\n",
    "        return 'Human'\n",
    "    else:\n",
    "        return 'Uncertain'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_few_shot(text):\n",
    "    prompt = f\"\"\"\n",
    "            You are an expert at distinguishing AI-generated from human-written text.\n",
    "            Read the third text carefully and classify it explicitly as either 'AI' (generated by artificial intelligence) or 'Human' (written by a real person), Use the information from the first two examples:\n",
    "            \n",
    "            Text: \"Although this technique was first thought of as a way to accurately define a standard unit of current, it turned out to be more useful in the field of quantum information. Usually, qubits are stationary, making the transfer of information between them difficult. The single electrons, carried by the SAWs, can be used as so called flying qubits, able to transport information from one place to another. To realise this a single electron source is needed, as well as a receiver between which the electron can be transported. Quantum dots (QD) are typically used for these stationary electron confinements. This potential minimum is sometimes called a SAW QD. The process, as seen in the GIF on the right, is typically as follows. First SAWs are generated with an interdigital transducer with specific dimensions between the electrodes to get the favorable wavelengths. Then from the stationary QD the electron quantum tunnels to the potential minimum, or SAW QD. The SAWs transfer some kinetic energy to the electron, driving it forward.\"\n",
    "            Classification: Human\n",
    "            \n",
    "            Text: \"Many scholars argue that the full potential of plate tectonics has yet to be realized, pointing to gaps in current models and empirical validation. With recent breakthroughs, plate tectonics is becoming increasingly relevant to modern scientific challenges, such as sustainability and artificial intelligence. Despite technical difficulties, plate tectonics continues to evolve through rigorous experimentation and continuous refinement of theories. Among the many branches of science, plate tectonics stands out for its complexity and potential to reshape our understanding of the world. Plate tectonics is a field that has witnessed dramatic transformations in recent years, with scientists exploring its implications across multiple domains. While some aspects of plate tectonics remain theoretical, its real-world applications are beginning to influence innovation and policy. The ongoing development of plate tectonics has sparked discussions not only about its scientific basis but also about its ethical and societal ramifications.\"\n",
    "            Classification: AI\n",
    "            \n",
    "            Text: \"While some aspects of chemical engineering remain theoretical, its real-world applications are beginning to influence innovation and policy. Academic interest in chemical engineering continues to grow as new tools and interdisciplinary frameworks provide fresh insights and unexpected results. The ongoing development of chemical engineering has sparked discussions not only about its scientific basis but also about its ethical and societal ramifications. Among the many branches of science, chemical engineering stands out for its complexity and potential to reshape our understanding of the world. In the study of chemical engineering, researchers continue to grapple with foundational questions that challenge long-held theories and methodologies. With recent breakthroughs, chemical engineering is becoming increasingly relevant to modern scientific challenges, such as sustainability and artificial intelligence. Despite technical difficulties, chemical engineering continues to evolve through rigorous experimentation and continuous refinement of theories. Efforts to understand chemical engineering often lead to collaborations between institutions, enabling faster progress and\"\n",
    "            Classification: AI\n",
    "            \n",
    "            Text: \"Clay chemistry is an applied subdiscipline of chemistry which studies the chemical structures, properties and reactions of or involving clays and clay minerals. It is a multidisciplinary field, involving concepts and knowledge from inorganic and structural chemistry, physical chemistry, materials chemistry, analytical chemistry, organic chemistry, mineralogy, geology and others. The study of the chemistry (and physics) of clays and clay minerals is of great academic and industrial relevance as they are among the most widely used industrial minerals, being employed as raw materials (ceramics, pottery, etc. ), adsorbents, catalysts, additives, mineral charges, medicines, building materials and others. The unique properties of clay minerals including: nanometric scale layered construction, presence of fixed and interchangeable charges, possibility of adsorbing and hosting (intercalating) molecules, ability of forming stable colloidal dispersions, possibility of tailored surface and interlayer chemical modification and others, make the study of clay chemistry a very important and extremely varied field of research.\"\n",
    "            Classification: Human\n",
    "            \n",
    "            \n",
    "             \n",
    "            Text:\n",
    "            \\\"\\\"\\\"\n",
    "            {text}\n",
    "            \\\"\\\"\\\"\n",
    "\n",
    "            Your response must strictly be either 'AI' or 'Human', with no further explanation:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    response = llm_model.generate_content(prompt)\n",
    "    print(f\"resposta: {response}\")\n",
    "    \n",
    "    classification = response.text.strip().lower()\n",
    "    \n",
    "    print(f\"classification: {classification}\")\n",
    "    \n",
    "    if 'ai' in classification:\n",
    "        return 'AI'\n",
    "    \n",
    "    elif 'human' in classification:\n",
    "        return 'Human'\n",
    "    else:\n",
    "        return 'Uncertain'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def retrieve_similar_texts(query_text, dataset_texts, dataset_labels, dataset_embeddings, top_k=3):\n",
    "    query_embedding = embedding_model.encode([query_text])\n",
    "    similarities = cosine_similarity(query_embedding, dataset_embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    retrieved = [(dataset_texts[i], dataset_labels[i]) for i in top_indices]\n",
    "    return retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_orag_prompt(retrieved_examples, query_text):\n",
    "    examples_formatted = \"\\n\".join(\n",
    "        [f'{idx+1}. \"{text}\" — Classification: {label}' for idx, (text, label) in enumerate(retrieved_examples)]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "            You are an expert at distinguishing AI-generated from human-written text. \n",
    "            Carefully analyze the provided similar examples retrieved specifically for this task, then classify the given text explicitly as \"AI\" or \"Human\".\n",
    "\n",
    "            Retrieved examples:\n",
    "            {examples_formatted}\n",
    "\n",
    "            Text to classify:\n",
    "            \"{query_text}\"\n",
    "\n",
    "            Your response must strictly be either \"AI\" or \"Human\", without any additional explanation:\n",
    "            \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_orag(query_text, dataset_texts, dataset_labels, dataset_embeddings, top_k=3):\n",
    "    # Recuperar exemplos semelhantes dinamicamente\n",
    "    retrieved_examples = retrieve_similar_texts(query_text, dataset_texts, dataset_labels, dataset_embeddings, top_k)\n",
    "\n",
    "    # Construir o prompt ORAG\n",
    "    prompt = build_orag_prompt(retrieved_examples, query_text)\n",
    "\n",
    "    response = llm_model.generate_content(prompt)\n",
    "    classification = response.text.strip().lower()\n",
    "\n",
    "    if 'ai' in classification:\n",
    "        return 'AI'\n",
    "    elif 'human' in classification:\n",
    "        return 'Human'\n",
    "    else:\n",
    "        return 'Uncertain'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler o arquivo de entrada\n",
    "df_test = pd.read_csv(\"data/dataset3_inputs.csv\", sep=';', on_bad_lines='skip')\n",
    "\n",
    "# Aplicar a previsão na coluna 'text'\n",
    "df_test['predicted'] = df_test['Text'].apply(classify_text_zero_shot)\n",
    "\n",
    "# Exibir o dataframe completo (opcional, para verificação)\n",
    "print(\"Dataframe completo com previsões:\")\n",
    "print(df_test)\n",
    "\n",
    "# Criar um novo dataframe com apenas 'ID' e 'Label' (usando a previsão como 'Label')\n",
    "df_output = df_test[['ID', 'predicted']].rename(columns={'predicted': 'Label'})\n",
    "\n",
    "# Exibir o novo dataframe (opcional, para verificação)\n",
    "print(\"\\nNovo dataframe com ID e Label:\")\n",
    "print(df_output)\n",
    "\n",
    "# Salvar o novo dataframe em um arquivo CSV\n",
    "df_output.to_csv('score/LLM_dataset3.csv', sep='\\t', index=False)\n",
    "print(\"\\nO dataset foi salvo no arquivo 'LLM_dataset1.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar seu dataset etiquetado\n",
    "df_train = pd.read_csv(\"data/fixed_dataset_final.csv\", sep=',')\n",
    "dataset_texts = df_train[\"Text\"].tolist()\n",
    "dataset_labels = df_train[\"Label\"].tolist()\n",
    "\n",
    "dataset_embeddings = embedding_model.encode(dataset_texts)\n",
    "\n",
    "df_test = pd.read_csv(\"data/dataset1_inputs.csv\", sep='\\t')\n",
    "\n",
    "# Aplicar ORAG para classificação dos textos\n",
    "df_test['Label'] = df_test['Text'].apply(\n",
    "    lambda x: classify_text_orag(x, dataset_texts, dataset_labels, dataset_embeddings)\n",
    ")\n",
    "\n",
    "df_test[['ID', 'Label']].to_csv(\"LLM_dataset1.csv\", sep='\\t', index=False)\n",
    "\n",
    "print(df_test[['ID', 'Label']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. Carregar os arquivos\n",
    "preds_df = pd.read_csv(\"score/LLM_dataset1.csv\", sep='\\t', on_bad_lines='skip')\n",
    "labels_df = pd.read_csv(\"data/dataset1_outputs.csv\", sep='\\t', on_bad_lines='skip')\n",
    "\n",
    "# 2. Garantir que as colunas corretas estão sendo usadas\n",
    "# Assumindo que a coluna de previsões se chama 'Pred' e a de verdade se chama 'Label'\n",
    "y_pred = preds_df['Label']\n",
    "y_true = labels_df['Label']\n",
    "\n",
    "# 3. Comparar previsões com os rótulos reais\n",
    "print(\"accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
