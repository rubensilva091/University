{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos with frames: 30\n"
     ]
    }
   ],
   "source": [
    "LABEL_PATH = Path(\"../data/labels/labels_task2.csv\")\n",
    "FRAME_DIR = Path(\"../data/frames\")\n",
    "\n",
    "df = pd.read_csv(LABEL_PATH)\n",
    "available_videos = {p.name for p in FRAME_DIR.iterdir() if p.is_dir() and any(p.glob(\"*.jpg\"))}\n",
    "df = df[df[\"VIDEO\"].isin(available_videos)].reset_index(drop=True)\n",
    "print(f\"Number of videos with frames: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSATSDataset(Dataset):\n",
    "    def __init__(self, dataframe, frame_dir, transform=None, sequence_length=16):\n",
    "        self.data = dataframe.copy()\n",
    "        self.frame_dir = frame_dir\n",
    "        self.transform = transform\n",
    "        self.sequence_length = sequence_length\n",
    "        self.osats_cols = [col for col in dataframe.columns if col.startswith(\"OSATS_\")]\n",
    "\n",
    "        for col in self.osats_cols:\n",
    "            self.data[col] = self.data[col].clip(0, 4).astype(np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        video_id = row[\"VIDEO\"]\n",
    "        y = row[self.osats_cols].values.astype(np.int64)\n",
    "        path = self.frame_dir / video_id\n",
    "\n",
    "        frames = sorted(path.glob(\"*.jpg\"))\n",
    "        selected = frames[:self.sequence_length]\n",
    "        if len(selected) == 0:\n",
    "            raise IndexError(f\"No frames for video {video_id}\")\n",
    "        while len(selected) < self.sequence_length:\n",
    "            selected.append(selected[-1])\n",
    "\n",
    "        images = [self.transform(Image.open(f).convert(\"RGB\")) for f in selected]\n",
    "        return torch.stack(images), torch.tensor(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transforms para imagens (compatível com CNNs e ResNet)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Colunas OSATS (as 8 que vais prever)\n",
    "osats_cols = [col for col in df.columns if col.startswith(\"OSATS_\")]\n",
    "\n",
    "# Criar uma coluna auxiliar com a média arredondada das OSATS para estratificação\n",
    "df[\"OSATS_MEAN_LABEL\"] = df[osats_cols].mean(axis=1).round().astype(int)\n",
    "\n",
    "# Divisão 70% treino, 30% temp (com estratificação)\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, test_size=0.30, random_state=42, stratify=df[\"OSATS_MEAN_LABEL\"]\n",
    ")\n",
    "\n",
    "# Divisão 15% validação, 15% teste (sem stratify para evitar erro)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Criação dos datasets\n",
    "train_dataset = OSATSDataset(train_df, FRAME_DIR, transform)\n",
    "val_dataset = OSATSDataset(val_df, FRAME_DIR, transform)\n",
    "test_dataset = OSATSDataset(test_df, FRAME_DIR, transform)\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.init import kaiming_uniform_, xavier_uniform_\n",
    "\n",
    "class CNNModel_1(nn.Module):\n",
    "    def __init__(self, num_classes=40, sequence_length=16, input_shape=(3,224,224)):\n",
    "        super(CNNModel_1, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_output((sequence_length, *input_shape))\n",
    "        self.fc1 = nn.Linear(conv_out_size, 100)\n",
    "        kaiming_uniform_(self.fc1.weight, nonlinearity='relu')\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "        xavier_uniform_(self.fc2.weight)\n",
    "        self.act2 = nn.Softmax(dim=1)\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        bs = 1\n",
    "        input = torch.rand(bs, *shape)\n",
    "        B, T, C, H, W = input.shape\n",
    "        input = input.view(B * T, C, H, W)\n",
    "        output_feat = self.layer1(input)\n",
    "        output_feat = self.layer2(output_feat)\n",
    "        output_feat = output_feat.view(output_feat.size(0), -1)\n",
    "        output_feat = output_feat.view(bs, T, -1).mean(dim=1)\n",
    "        return int(np.prod(output_feat.size()[1:]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = out.view(B, T, -1).mean(dim=1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.act1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.act2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_2(nn.Module):\n",
    "    def __init__(self, num_classes=40, sequence_length=16, input_shape=(3,224,224)):\n",
    "        super(CNNModel_2, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_output((sequence_length, *input_shape))\n",
    "        self.fc1 = nn.Linear(conv_out_size, num_classes)\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        bs = 1\n",
    "        input = torch.rand(bs, *shape)\n",
    "        B, T, C, H, W = input.shape\n",
    "        input = input.view(B * T, C, H, W)\n",
    "        output_feat = self.layer1(input)\n",
    "        output_feat = self.layer2(output_feat)\n",
    "        output_feat = output_feat.view(output_feat.size(0), -1)\n",
    "        output_feat = output_feat.view(bs, T, -1).mean(dim=1)\n",
    "        return int(np.prod(output_feat.size()[1:]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = out.view(B, T, -1).mean(dim=1)\n",
    "        out = self.fc1(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BatchNorm2d, Dropout\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNModel_3(nn.Module):\n",
    "    def __init__(self, num_classes=40, sequence_length=16, input_shape=(3,224,224)):\n",
    "        super(CNNModel_3, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_output((sequence_length, *input_shape))\n",
    "        self.fc1 = nn.Linear(conv_out_size, 600)\n",
    "        self.drop = Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(600, 120)\n",
    "        self.fc3 = nn.Linear(120, num_classes)\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        bs = 1\n",
    "        input = torch.rand(bs, *shape)\n",
    "        B, T, C, H, W = input.shape\n",
    "        input = input.view(B * T, C, H, W)\n",
    "        output_feat = self.layer1(input)\n",
    "        output_feat = self.layer2(output_feat)\n",
    "        output_feat = output_feat.view(output_feat.size(0), -1)\n",
    "        output_feat = output_feat.view(bs, T, -1).mean(dim=1)\n",
    "        return int(np.prod(output_feat.size()[1:]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = out.view(B, T, -1).mean(dim=1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.drop(out)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Dropout2d\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNModel_4(nn.Module):\n",
    "    def __init__(self, num_classes=40, sequence_length=16, input_shape=(3,224,224)):\n",
    "        super(CNNModel_4, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            Dropout2d(0.2)\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_output((sequence_length, *input_shape))\n",
    "        self.fc1 = nn.Linear(conv_out_size, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        bs = 1\n",
    "        input = torch.rand(bs, *shape)\n",
    "        B, T, C, H, W = input.shape\n",
    "        input = input.view(B * T, C, H, W)\n",
    "        output_feat = self.layer1(input)\n",
    "        output_feat = output_feat.view(output_feat.size(0), -1)\n",
    "        output_feat = output_feat.view(bs, T, -1).mean(dim=1)\n",
    "        return int(np.prod(output_feat.size()[1:]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        out = self.layer1(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = out.view(B, T, -1).mean(dim=1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, epochs):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            if targets.dim() > 1:\n",
    "                targets = targets[:, 0]\n",
    "\n",
    "            if outputs.shape[0] != targets.shape[0]:\n",
    "                raise ValueError(f\"Shape mismatch: outputs {outputs.shape} vs targets {targets.shape}\")\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(dataloader):.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            if targets.dim() > 1:\n",
    "                targets = targets[:, 0]\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Accuracy: {acc:.2f}%\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 3.5637\n",
      "Epoch [2/100], Loss: 3.3971\n",
      "Epoch [3/100], Loss: 3.3976\n",
      "Epoch [4/100], Loss: 3.2726\n",
      "Epoch [5/100], Loss: 3.2726\n",
      "Epoch [6/100], Loss: 3.2726\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model1 \u001b[38;5;241m=\u001b[39m CNNModel_1(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, sequence_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m224\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m model1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidação - Modelo 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m evaluate_model(model1, val_loader)\n",
      "Cell \u001b[0;32mIn[14], line 22\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, epochs)\u001b[0m\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 22\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     24\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/ap/lib/python3.9/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ap/lib/python3.9/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ap/lib/python3.9/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1 = CNNModel_1(num_classes=40, sequence_length=16, input_shape=(3,224,224))\n",
    "model1 = train_model(model1, train_loader, epochs=100)\n",
    "\n",
    "print(\"Validação - Modelo 1\")\n",
    "evaluate_model(model1, val_loader)\n",
    "\n",
    "print(\"Teste - Modelo 1\")\n",
    "evaluate_model(model1, test_loader)\n",
    "\n",
    "# Guardar modelo com nome especificado\n",
    "torch.save(model1.state_dict(), \"../outputs/models/model_task2_cnn1.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 2.2780\n",
      "Epoch [2/100], Loss: 1.1471\n",
      "Epoch [3/100], Loss: 1.0207\n",
      "Epoch [4/100], Loss: 0.8331\n",
      "Epoch [5/100], Loss: 0.6566\n",
      "Epoch [6/100], Loss: 0.5938\n",
      "Epoch [7/100], Loss: 0.4651\n",
      "Epoch [8/100], Loss: 0.5090\n",
      "Epoch [9/100], Loss: 0.3157\n",
      "Epoch [10/100], Loss: 0.3054\n",
      "Epoch [11/100], Loss: 0.2842\n",
      "Epoch [12/100], Loss: 0.1382\n",
      "Epoch [13/100], Loss: 0.1478\n",
      "Epoch [14/100], Loss: 0.1138\n",
      "Epoch [15/100], Loss: 0.0969\n",
      "Epoch [16/100], Loss: 0.0678\n",
      "Epoch [17/100], Loss: 0.0536\n",
      "Epoch [18/100], Loss: 0.0413\n",
      "Epoch [19/100], Loss: 0.0315\n",
      "Epoch [20/100], Loss: 0.0286\n",
      "Epoch [21/100], Loss: 0.0262\n",
      "Epoch [22/100], Loss: 0.0334\n",
      "Epoch [23/100], Loss: 0.0216\n",
      "Epoch [24/100], Loss: 0.0203\n",
      "Epoch [25/100], Loss: 0.0154\n",
      "Epoch [26/100], Loss: 0.0149\n",
      "Epoch [27/100], Loss: 0.0125\n",
      "Epoch [28/100], Loss: 0.0122\n",
      "Epoch [29/100], Loss: 0.0099\n",
      "Epoch [30/100], Loss: 0.0092\n",
      "Epoch [31/100], Loss: 0.0084\n",
      "Epoch [32/100], Loss: 0.0101\n",
      "Epoch [33/100], Loss: 0.0070\n",
      "Epoch [34/100], Loss: 0.0070\n",
      "Epoch [35/100], Loss: 0.0079\n",
      "Epoch [36/100], Loss: 0.0063\n",
      "Epoch [37/100], Loss: 0.0060\n",
      "Epoch [38/100], Loss: 0.0067\n",
      "Epoch [39/100], Loss: 0.0053\n",
      "Epoch [40/100], Loss: 0.0051\n",
      "Epoch [41/100], Loss: 0.0044\n",
      "Epoch [42/100], Loss: 0.0041\n",
      "Epoch [43/100], Loss: 0.0038\n",
      "Epoch [44/100], Loss: 0.0036\n",
      "Epoch [45/100], Loss: 0.0034\n",
      "Epoch [46/100], Loss: 0.0035\n",
      "Epoch [47/100], Loss: 0.0042\n",
      "Epoch [48/100], Loss: 0.0036\n",
      "Epoch [49/100], Loss: 0.0032\n",
      "Epoch [50/100], Loss: 0.0027\n",
      "Epoch [51/100], Loss: 0.0030\n",
      "Epoch [52/100], Loss: 0.0024\n",
      "Epoch [53/100], Loss: 0.0026\n",
      "Epoch [54/100], Loss: 0.0024\n",
      "Epoch [55/100], Loss: 0.0023\n",
      "Epoch [56/100], Loss: 0.0022\n",
      "Epoch [57/100], Loss: 0.0028\n",
      "Epoch [58/100], Loss: 0.0021\n",
      "Epoch [59/100], Loss: 0.0019\n",
      "Epoch [60/100], Loss: 0.0023\n",
      "Epoch [61/100], Loss: 0.0019\n",
      "Epoch [62/100], Loss: 0.0019\n",
      "Epoch [63/100], Loss: 0.0017\n",
      "Epoch [64/100], Loss: 0.0016\n",
      "Epoch [65/100], Loss: 0.0016\n",
      "Epoch [66/100], Loss: 0.0015\n",
      "Epoch [67/100], Loss: 0.0013\n",
      "Epoch [68/100], Loss: 0.0014\n",
      "Epoch [69/100], Loss: 0.0013\n",
      "Epoch [70/100], Loss: 0.0013\n",
      "Epoch [71/100], Loss: 0.0012\n",
      "Epoch [72/100], Loss: 0.0012\n",
      "Epoch [73/100], Loss: 0.0012\n",
      "Epoch [74/100], Loss: 0.0014\n",
      "Epoch [75/100], Loss: 0.0011\n",
      "Epoch [76/100], Loss: 0.0011\n",
      "Epoch [77/100], Loss: 0.0012\n",
      "Epoch [78/100], Loss: 0.0011\n",
      "Epoch [79/100], Loss: 0.0013\n",
      "Epoch [80/100], Loss: 0.0012\n",
      "Epoch [81/100], Loss: 0.0010\n",
      "Epoch [82/100], Loss: 0.0010\n",
      "Epoch [83/100], Loss: 0.0009\n",
      "Epoch [84/100], Loss: 0.0009\n",
      "Epoch [85/100], Loss: 0.0009\n",
      "Epoch [86/100], Loss: 0.0008\n",
      "Epoch [87/100], Loss: 0.0011\n",
      "Epoch [88/100], Loss: 0.0008\n",
      "Epoch [89/100], Loss: 0.0008\n",
      "Epoch [90/100], Loss: 0.0010\n",
      "Epoch [91/100], Loss: 0.0008\n",
      "Epoch [92/100], Loss: 0.0008\n",
      "Epoch [93/100], Loss: 0.0008\n",
      "Epoch [94/100], Loss: 0.0008\n",
      "Epoch [95/100], Loss: 0.0006\n",
      "Epoch [96/100], Loss: 0.0007\n",
      "Epoch [97/100], Loss: 0.0007\n",
      "Epoch [98/100], Loss: 0.0007\n",
      "Epoch [99/100], Loss: 0.0006\n",
      "Epoch [100/100], Loss: 0.0007\n",
      "Validação - Modelo 2\n",
      "Accuracy: 25.00%\n",
      "Teste - Modelo 2\n",
      "Accuracy: 20.00%\n"
     ]
    }
   ],
   "source": [
    "model2 = CNNModel_2(num_classes=40, sequence_length=16, input_shape=(3,224,224))\n",
    "model2 = train_model(model2, train_loader, epochs=100)\n",
    "\n",
    "print(\"Validação - Modelo 2\")\n",
    "evaluate_model(model2, val_loader)\n",
    "\n",
    "print(\"Teste - Modelo 2\")\n",
    "evaluate_model(model2, test_loader)\n",
    "\n",
    "torch.save(model2.state_dict(), \"../outputs/models/model_task2_cnn2.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 4.2357\n",
      "Epoch [2/100], Loss: 1.9221\n",
      "Epoch [3/100], Loss: 1.1928\n",
      "Epoch [4/100], Loss: 1.5472\n",
      "Epoch [5/100], Loss: 0.6307\n",
      "Epoch [6/100], Loss: 0.3455\n",
      "Epoch [7/100], Loss: 0.5239\n",
      "Epoch [8/100], Loss: 0.4486\n",
      "Epoch [9/100], Loss: 0.0568\n",
      "Epoch [10/100], Loss: 0.1511\n",
      "Epoch [11/100], Loss: 0.0928\n",
      "Epoch [12/100], Loss: 0.2287\n",
      "Epoch [13/100], Loss: 0.0276\n",
      "Epoch [14/100], Loss: 0.4409\n",
      "Epoch [15/100], Loss: 0.0475\n",
      "Epoch [16/100], Loss: 0.0026\n",
      "Epoch [17/100], Loss: 0.0180\n",
      "Epoch [18/100], Loss: 0.0077\n",
      "Epoch [19/100], Loss: 0.0097\n",
      "Epoch [20/100], Loss: 0.0014\n",
      "Epoch [21/100], Loss: 0.0012\n",
      "Epoch [22/100], Loss: 0.0001\n",
      "Epoch [23/100], Loss: 0.0003\n",
      "Epoch [24/100], Loss: 0.0009\n",
      "Epoch [25/100], Loss: 0.0009\n",
      "Epoch [26/100], Loss: 0.0002\n",
      "Epoch [27/100], Loss: 0.0010\n",
      "Epoch [28/100], Loss: 0.0002\n",
      "Epoch [29/100], Loss: 0.0018\n",
      "Epoch [30/100], Loss: 0.0002\n",
      "Epoch [31/100], Loss: 0.0033\n",
      "Epoch [32/100], Loss: 0.0013\n",
      "Epoch [33/100], Loss: 0.0006\n",
      "Epoch [34/100], Loss: 0.0001\n",
      "Epoch [35/100], Loss: 0.0036\n",
      "Epoch [36/100], Loss: 0.0004\n",
      "Epoch [37/100], Loss: 0.0011\n",
      "Epoch [38/100], Loss: 0.0001\n",
      "Epoch [39/100], Loss: 0.0005\n",
      "Epoch [40/100], Loss: 0.0000\n",
      "Epoch [41/100], Loss: 0.0001\n",
      "Epoch [42/100], Loss: 0.0007\n",
      "Epoch [43/100], Loss: 0.0165\n",
      "Epoch [44/100], Loss: 0.0000\n",
      "Epoch [45/100], Loss: 0.0017\n",
      "Epoch [46/100], Loss: 0.0100\n",
      "Epoch [47/100], Loss: 0.0004\n",
      "Epoch [48/100], Loss: 0.0016\n",
      "Epoch [49/100], Loss: 0.0000\n",
      "Epoch [50/100], Loss: 0.0002\n",
      "Epoch [51/100], Loss: 0.0001\n",
      "Epoch [52/100], Loss: 0.0004\n",
      "Epoch [53/100], Loss: 0.0001\n",
      "Epoch [54/100], Loss: 0.0002\n",
      "Epoch [55/100], Loss: 0.0005\n",
      "Epoch [56/100], Loss: 0.0001\n",
      "Epoch [57/100], Loss: 0.0001\n",
      "Epoch [58/100], Loss: 0.0000\n",
      "Epoch [59/100], Loss: 0.0000\n",
      "Epoch [60/100], Loss: 0.0002\n",
      "Epoch [61/100], Loss: 0.0012\n",
      "Epoch [62/100], Loss: 0.0000\n",
      "Epoch [63/100], Loss: 0.0002\n",
      "Epoch [64/100], Loss: 0.0002\n",
      "Epoch [65/100], Loss: 0.0000\n",
      "Epoch [66/100], Loss: 0.0003\n",
      "Epoch [67/100], Loss: 0.0002\n",
      "Epoch [68/100], Loss: 0.0006\n",
      "Epoch [69/100], Loss: 0.0002\n",
      "Epoch [70/100], Loss: 0.0031\n",
      "Epoch [71/100], Loss: 0.0001\n",
      "Epoch [72/100], Loss: 0.0000\n",
      "Epoch [73/100], Loss: 0.0001\n",
      "Epoch [74/100], Loss: 0.0001\n",
      "Epoch [75/100], Loss: 0.0000\n",
      "Epoch [76/100], Loss: 0.0001\n",
      "Epoch [77/100], Loss: 0.0006\n",
      "Epoch [78/100], Loss: 0.0003\n",
      "Epoch [79/100], Loss: 0.0002\n",
      "Epoch [80/100], Loss: 0.0000\n",
      "Epoch [81/100], Loss: 0.0002\n",
      "Epoch [82/100], Loss: 0.0000\n",
      "Epoch [83/100], Loss: 0.0001\n",
      "Epoch [84/100], Loss: 0.0001\n",
      "Epoch [85/100], Loss: 0.0000\n",
      "Epoch [86/100], Loss: 0.0001\n",
      "Epoch [87/100], Loss: 0.0001\n",
      "Epoch [88/100], Loss: 0.0009\n",
      "Epoch [89/100], Loss: 0.0039\n",
      "Epoch [90/100], Loss: 0.0001\n",
      "Epoch [91/100], Loss: 0.0001\n",
      "Epoch [92/100], Loss: 0.0000\n",
      "Epoch [93/100], Loss: 0.0008\n",
      "Epoch [94/100], Loss: 0.0001\n",
      "Epoch [95/100], Loss: 0.0000\n",
      "Epoch [96/100], Loss: 0.0005\n",
      "Epoch [97/100], Loss: 0.0000\n",
      "Epoch [98/100], Loss: 0.0006\n",
      "Epoch [99/100], Loss: 0.0000\n",
      "Epoch [100/100], Loss: 0.0000\n",
      "Validação - Modelo 3\n",
      "Accuracy: 25.00%\n",
      "Teste - Modelo 3\n",
      "Accuracy: 40.00%\n"
     ]
    }
   ],
   "source": [
    "model3 = CNNModel_3(num_classes=40, sequence_length=16, input_shape=(3,224,224))\n",
    "model3 = train_model(model3, train_loader, epochs=100)\n",
    "\n",
    "print(\"Validação - Modelo 3\")\n",
    "evaluate_model(model3, val_loader)\n",
    "\n",
    "print(\"Teste - Modelo 3\")\n",
    "evaluate_model(model3, test_loader)\n",
    "\n",
    "torch.save(model3.state_dict(), \"../outputs/models/model_task2_cnn3.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 8.6049\n",
      "Epoch [2/100], Loss: 8.4234\n",
      "Epoch [3/100], Loss: 6.4934\n",
      "Epoch [4/100], Loss: 3.9202\n",
      "Epoch [5/100], Loss: 3.8293\n",
      "Epoch [6/100], Loss: 0.8885\n",
      "Epoch [7/100], Loss: 0.1558\n",
      "Epoch [8/100], Loss: 0.0006\n",
      "Epoch [9/100], Loss: 0.5408\n",
      "Epoch [10/100], Loss: 0.0000\n",
      "Epoch [11/100], Loss: 0.0001\n",
      "Epoch [12/100], Loss: 0.0022\n",
      "Epoch [13/100], Loss: 0.0641\n",
      "Epoch [14/100], Loss: 0.0002\n",
      "Epoch [15/100], Loss: 0.0006\n",
      "Epoch [16/100], Loss: 0.0024\n",
      "Epoch [17/100], Loss: 0.0018\n",
      "Epoch [18/100], Loss: 0.0013\n",
      "Epoch [19/100], Loss: 0.0001\n",
      "Epoch [20/100], Loss: 0.0000\n",
      "Epoch [21/100], Loss: 0.0000\n",
      "Epoch [22/100], Loss: 0.0000\n",
      "Epoch [23/100], Loss: 0.0001\n",
      "Epoch [24/100], Loss: 0.0000\n",
      "Epoch [25/100], Loss: 0.0000\n",
      "Epoch [26/100], Loss: 0.0000\n",
      "Epoch [27/100], Loss: 0.0000\n",
      "Epoch [28/100], Loss: 0.0000\n",
      "Epoch [29/100], Loss: 0.0000\n",
      "Epoch [30/100], Loss: 0.0000\n",
      "Epoch [31/100], Loss: 0.0000\n",
      "Epoch [32/100], Loss: 0.0000\n",
      "Epoch [33/100], Loss: 0.0000\n",
      "Epoch [34/100], Loss: 0.0000\n",
      "Epoch [35/100], Loss: 0.0001\n",
      "Epoch [36/100], Loss: 0.0000\n",
      "Epoch [37/100], Loss: 0.0000\n",
      "Epoch [38/100], Loss: 0.0000\n",
      "Epoch [39/100], Loss: 0.0000\n",
      "Epoch [40/100], Loss: 0.0000\n",
      "Epoch [41/100], Loss: 0.0000\n",
      "Epoch [42/100], Loss: 0.0000\n",
      "Epoch [43/100], Loss: 0.0000\n",
      "Epoch [44/100], Loss: 0.0000\n",
      "Epoch [45/100], Loss: 0.0000\n",
      "Epoch [46/100], Loss: 0.0000\n",
      "Epoch [47/100], Loss: 0.0000\n",
      "Epoch [48/100], Loss: 0.0000\n",
      "Epoch [49/100], Loss: 0.0000\n",
      "Epoch [50/100], Loss: 0.0000\n",
      "Epoch [51/100], Loss: 0.0000\n",
      "Epoch [52/100], Loss: 0.0000\n",
      "Epoch [53/100], Loss: 0.0000\n",
      "Epoch [54/100], Loss: 0.0000\n",
      "Epoch [55/100], Loss: 0.0000\n",
      "Epoch [56/100], Loss: 0.0000\n",
      "Epoch [57/100], Loss: 0.0000\n",
      "Epoch [58/100], Loss: 0.0000\n",
      "Epoch [59/100], Loss: 0.0000\n",
      "Epoch [60/100], Loss: 0.0000\n",
      "Epoch [61/100], Loss: 0.0000\n",
      "Epoch [62/100], Loss: 0.0000\n",
      "Epoch [63/100], Loss: 0.0000\n",
      "Epoch [64/100], Loss: 0.0000\n",
      "Epoch [65/100], Loss: 0.0000\n",
      "Epoch [66/100], Loss: 0.0000\n",
      "Epoch [67/100], Loss: 0.0000\n",
      "Epoch [68/100], Loss: 0.0000\n",
      "Epoch [69/100], Loss: 0.0000\n",
      "Epoch [70/100], Loss: 0.0000\n",
      "Epoch [71/100], Loss: 0.0000\n",
      "Epoch [72/100], Loss: 0.0000\n",
      "Epoch [73/100], Loss: 0.0000\n",
      "Epoch [74/100], Loss: 0.0000\n",
      "Epoch [75/100], Loss: 0.0000\n",
      "Epoch [76/100], Loss: 0.0000\n",
      "Epoch [77/100], Loss: 0.0000\n",
      "Epoch [78/100], Loss: 0.0000\n",
      "Epoch [79/100], Loss: 0.0000\n",
      "Epoch [80/100], Loss: 0.0000\n",
      "Epoch [81/100], Loss: 0.0000\n",
      "Epoch [82/100], Loss: 0.0000\n",
      "Epoch [83/100], Loss: 0.0000\n",
      "Epoch [84/100], Loss: 0.0000\n",
      "Epoch [85/100], Loss: 0.0000\n",
      "Epoch [86/100], Loss: 0.0000\n",
      "Epoch [87/100], Loss: 0.0000\n",
      "Epoch [88/100], Loss: 0.0000\n",
      "Epoch [89/100], Loss: 0.0000\n",
      "Epoch [90/100], Loss: 0.0000\n",
      "Epoch [91/100], Loss: 0.0000\n",
      "Epoch [92/100], Loss: 0.0000\n",
      "Epoch [93/100], Loss: 0.0000\n",
      "Epoch [94/100], Loss: 0.0000\n",
      "Epoch [95/100], Loss: 0.0000\n",
      "Epoch [96/100], Loss: 0.0000\n",
      "Epoch [97/100], Loss: 0.0000\n",
      "Epoch [98/100], Loss: 0.0000\n",
      "Epoch [99/100], Loss: 0.0000\n",
      "Epoch [100/100], Loss: 0.0000\n",
      "Validação - Modelo 4\n",
      "Accuracy: 25.00%\n",
      "Teste - Modelo 4\n",
      "Accuracy: 20.00%\n"
     ]
    }
   ],
   "source": [
    "model4 = CNNModel_4(num_classes=40, sequence_length=16, input_shape=(3,224,224))\n",
    "model4 = train_model(model4, train_loader, epochs=100)\n",
    "\n",
    "print(\"Validação - Modelo 4\")\n",
    "evaluate_model(model4, val_loader)\n",
    "\n",
    "print(\"Teste - Modelo 4\")\n",
    "evaluate_model(model4, test_loader)\n",
    "\n",
    "torch.save(model4.state_dict(), \"../outputs/models/model_task2_cnn4.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet18 + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrigindo escala de labels de 1–5 para 0–4...\n"
     ]
    }
   ],
   "source": [
    "frame_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def load_video_frames(video_path, max_frames=16):\n",
    "    frames = sorted(video_path.glob(\"*.jpg\"))[:max_frames]\n",
    "    video_tensor = torch.stack([frame_transform(Image.open(f).convert(\"RGB\")) for f in frames])\n",
    "    if len(frames) < max_frames:\n",
    "        padding = torch.zeros((max_frames - len(frames), 3, 224, 224))\n",
    "        video_tensor = torch.cat([video_tensor, padding], dim=0)\n",
    "    return video_tensor\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    video_id = row[\"VIDEO\"]\n",
    "    video_dir = FRAME_DIR / video_id\n",
    "    if not video_dir.exists():\n",
    "        continue\n",
    "    video_tensor = load_video_frames(video_dir, max_frames=16)\n",
    "    labels = torch.tensor([\n",
    "        row[\"OSATS_RESPECT\"], row[\"OSATS_MOTION\"], row[\"OSATS_INSTRUMENT\"],\n",
    "        row[\"OSATS_SUTURE\"], row[\"OSATS_FLOW\"], row[\"OSATS_KNOWLEDGE\"],\n",
    "        row[\"OSATS_PERFORMANCE\"], row[\"OSATS_FINAL_QUALITY\"]\n",
    "    ], dtype=torch.long)\n",
    "    X.append(video_tensor)\n",
    "    y.append(labels)\n",
    "\n",
    "X = torch.stack(X)\n",
    "y = torch.stack(y)\n",
    "\n",
    "# Corrigir labels se estiverem na escala 1–5 (passar para 0–4)\n",
    "if torch.any(y > 4):\n",
    "    print(\"Corrigindo escala de labels de 1–5 para 0–4...\")\n",
    "    y = y - 1\n",
    "\n",
    "# Verificação de segurança\n",
    "assert torch.all((y >= 0) & (y <= 4)), \"Erro: targets fora do intervalo 0–4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "class OSATSDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = OSATSDataset(X, y)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSATSResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        resnet.fc = nn.Identity()\n",
    "        self.backbone = resnet\n",
    "        self.fc_shared = nn.Linear(512, 128)\n",
    "        self.heads = nn.ModuleList([nn.Linear(128, 5) for _ in range(8)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        feat = self.backbone(x).view(B, T, -1)\n",
    "        feat = feat.mean(dim=1)\n",
    "        shared = F.relu(self.fc_shared(feat))\n",
    "        return torch.stack([head(shared) for head in self.heads], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def compute_loss(preds, targets):\n",
    "    loss = 0\n",
    "    for i in range(8):\n",
    "        loss += loss_fn(preds[:, i], targets[:, i])\n",
    "    return loss / 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/miniconda3/envs/ap/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/luis/miniconda3/envs/ap/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1/100 - Loss treino: 1.6255\n",
      "Época 2/100 - Loss treino: 1.3395\n",
      "Época 3/100 - Loss treino: 1.1353\n",
      "Época 4/100 - Loss treino: 0.9684\n",
      "Época 5/100 - Loss treino: 0.8264\n",
      "Época 6/100 - Loss treino: 0.7052\n",
      "Época 7/100 - Loss treino: 0.5988\n",
      "Época 8/100 - Loss treino: 0.5056\n",
      "Época 9/100 - Loss treino: 0.4282\n",
      "Época 10/100 - Loss treino: 0.3620\n",
      "Época 11/100 - Loss treino: 0.3048\n",
      "Época 12/100 - Loss treino: 0.2565\n",
      "Época 13/100 - Loss treino: 0.2155\n",
      "Época 14/100 - Loss treino: 0.1806\n",
      "Época 15/100 - Loss treino: 0.1512\n",
      "Época 16/100 - Loss treino: 0.1267\n",
      "Época 17/100 - Loss treino: 0.1064\n",
      "Época 18/100 - Loss treino: 0.0895\n",
      "Época 19/100 - Loss treino: 0.0755\n",
      "Época 20/100 - Loss treino: 0.0640\n",
      "Época 21/100 - Loss treino: 0.0545\n",
      "Época 22/100 - Loss treino: 0.0467\n",
      "Época 23/100 - Loss treino: 0.0402\n",
      "Época 24/100 - Loss treino: 0.0348\n",
      "Época 25/100 - Loss treino: 0.0304\n",
      "Época 26/100 - Loss treino: 0.0266\n",
      "Época 27/100 - Loss treino: 0.0234\n",
      "Época 28/100 - Loss treino: 0.0208\n",
      "Época 29/100 - Loss treino: 0.0185\n",
      "Época 30/100 - Loss treino: 0.0166\n",
      "Época 31/100 - Loss treino: 0.0149\n",
      "Época 32/100 - Loss treino: 0.0135\n",
      "Época 33/100 - Loss treino: 0.0122\n",
      "Época 34/100 - Loss treino: 0.0111\n",
      "Época 35/100 - Loss treino: 0.0102\n",
      "Época 36/100 - Loss treino: 0.0093\n",
      "Época 37/100 - Loss treino: 0.0086\n",
      "Época 38/100 - Loss treino: 0.0080\n",
      "Época 39/100 - Loss treino: 0.0074\n",
      "Época 40/100 - Loss treino: 0.0069\n",
      "Época 41/100 - Loss treino: 0.0064\n",
      "Época 42/100 - Loss treino: 0.0060\n",
      "Época 43/100 - Loss treino: 0.0057\n",
      "Época 44/100 - Loss treino: 0.0053\n",
      "Época 45/100 - Loss treino: 0.0050\n",
      "Época 46/100 - Loss treino: 0.0048\n",
      "Época 47/100 - Loss treino: 0.0045\n",
      "Época 48/100 - Loss treino: 0.0043\n",
      "Época 49/100 - Loss treino: 0.0041\n",
      "Época 50/100 - Loss treino: 0.0039\n",
      "Época 51/100 - Loss treino: 0.0038\n",
      "Época 52/100 - Loss treino: 0.0036\n",
      "Época 53/100 - Loss treino: 0.0035\n",
      "Época 54/100 - Loss treino: 0.0033\n",
      "Época 55/100 - Loss treino: 0.0032\n",
      "Época 56/100 - Loss treino: 0.0031\n",
      "Época 57/100 - Loss treino: 0.0030\n",
      "Época 58/100 - Loss treino: 0.0029\n",
      "Época 59/100 - Loss treino: 0.0028\n",
      "Época 60/100 - Loss treino: 0.0027\n",
      "Época 61/100 - Loss treino: 0.0026\n",
      "Época 62/100 - Loss treino: 0.0026\n",
      "Época 63/100 - Loss treino: 0.0025\n",
      "Época 64/100 - Loss treino: 0.0024\n",
      "Época 65/100 - Loss treino: 0.0023\n",
      "Época 66/100 - Loss treino: 0.0023\n",
      "Época 67/100 - Loss treino: 0.0022\n",
      "Época 68/100 - Loss treino: 0.0022\n",
      "Época 69/100 - Loss treino: 0.0021\n",
      "Época 70/100 - Loss treino: 0.0021\n",
      "Época 71/100 - Loss treino: 0.0020\n",
      "Época 72/100 - Loss treino: 0.0020\n",
      "Época 73/100 - Loss treino: 0.0019\n",
      "Época 74/100 - Loss treino: 0.0019\n",
      "Época 75/100 - Loss treino: 0.0018\n",
      "Época 76/100 - Loss treino: 0.0018\n",
      "Época 77/100 - Loss treino: 0.0018\n",
      "Época 78/100 - Loss treino: 0.0017\n",
      "Época 79/100 - Loss treino: 0.0017\n",
      "Época 80/100 - Loss treino: 0.0017\n",
      "Época 81/100 - Loss treino: 0.0016\n",
      "Época 82/100 - Loss treino: 0.0016\n",
      "Época 83/100 - Loss treino: 0.0016\n",
      "Época 84/100 - Loss treino: 0.0015\n",
      "Época 85/100 - Loss treino: 0.0015\n",
      "Época 86/100 - Loss treino: 0.0015\n",
      "Época 87/100 - Loss treino: 0.0014\n",
      "Época 88/100 - Loss treino: 0.0014\n",
      "Época 89/100 - Loss treino: 0.0014\n",
      "Época 90/100 - Loss treino: 0.0014\n",
      "Época 91/100 - Loss treino: 0.0013\n",
      "Época 92/100 - Loss treino: 0.0013\n",
      "Época 93/100 - Loss treino: 0.0013\n",
      "Época 94/100 - Loss treino: 0.0013\n",
      "Época 95/100 - Loss treino: 0.0012\n",
      "Época 96/100 - Loss treino: 0.0012\n",
      "Época 97/100 - Loss treino: 0.0012\n",
      "Época 98/100 - Loss treino: 0.0012\n",
      "Época 99/100 - Loss treino: 0.0012\n",
      "Época 100/100 - Loss treino: 0.0011\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = OSATSResNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    all_preds, all_targets = [], []\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = compute_loss(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        preds = torch.argmax(outputs, dim=2)\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_targets.append(targets.cpu())\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    print(f\"Época {epoch+1}/{num_epochs} - Loss treino: {avg_loss:.4f}\")\n",
    "\n",
    "# Guardar o modelo após treino\n",
    "torch.save(model.state_dict(), \"../outputs/models/model_task2_resnet.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet18 + GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSATSResNetGRU(nn.Module):\n",
    "    def __init__(self, hidden_size=128, num_layers=1):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        resnet.fc = nn.Identity()\n",
    "        self.backbone = resnet  \n",
    "\n",
    "        self.gru = nn.GRU(input_size=512, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.heads = nn.ModuleList([nn.Linear(hidden_size, 5) for _ in range(8)])  \n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        features = self.backbone(x)  \n",
    "        features = features.view(B, T, 512) \n",
    "\n",
    "        _, h_n = self.gru(features) \n",
    "        h_n = h_n.squeeze(0) \n",
    "\n",
    "        return torch.stack([head(h_n) for head in self.heads], dim=1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(preds, targets):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for i in range(preds.size(1)):  # 8 cabeças\n",
    "        total_loss += loss_fn(preds[:, i], targets[:, i])\n",
    "    \n",
    "    return total_loss / preds.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1/100 - Loss treino: 1.6660\n",
      "Época 2/100 - Loss treino: 1.1489\n",
      "Época 3/100 - Loss treino: 0.9110\n",
      "Época 4/100 - Loss treino: 0.7746\n",
      "Época 5/100 - Loss treino: 0.6877\n",
      "Época 6/100 - Loss treino: 0.6271\n",
      "Época 7/100 - Loss treino: 0.5789\n",
      "Época 8/100 - Loss treino: 0.5406\n",
      "Época 9/100 - Loss treino: 0.5102\n",
      "Época 10/100 - Loss treino: 0.4848\n",
      "Época 11/100 - Loss treino: 0.4616\n",
      "Época 12/100 - Loss treino: 0.4415\n",
      "Época 13/100 - Loss treino: 0.4231\n",
      "Época 14/100 - Loss treino: 0.4061\n",
      "Época 15/100 - Loss treino: 0.3901\n",
      "Época 16/100 - Loss treino: 0.3744\n",
      "Época 17/100 - Loss treino: 0.3612\n",
      "Época 18/100 - Loss treino: 0.3490\n",
      "Época 19/100 - Loss treino: 0.3374\n",
      "Época 20/100 - Loss treino: 0.3264\n",
      "Época 21/100 - Loss treino: 0.3158\n",
      "Época 22/100 - Loss treino: 0.3057\n",
      "Época 23/100 - Loss treino: 0.2960\n",
      "Época 24/100 - Loss treino: 0.2868\n",
      "Época 25/100 - Loss treino: 0.2781\n",
      "Época 26/100 - Loss treino: 0.2699\n",
      "Época 27/100 - Loss treino: 0.2620\n",
      "Época 28/100 - Loss treino: 0.2542\n",
      "Época 29/100 - Loss treino: 0.2468\n",
      "Época 30/100 - Loss treino: 0.2398\n",
      "Época 31/100 - Loss treino: 0.2332\n",
      "Época 32/100 - Loss treino: 0.2268\n",
      "Época 33/100 - Loss treino: 0.2206\n",
      "Época 34/100 - Loss treino: 0.2145\n",
      "Época 35/100 - Loss treino: 0.2084\n",
      "Época 36/100 - Loss treino: 0.2024\n",
      "Época 37/100 - Loss treino: 0.1972\n",
      "Época 38/100 - Loss treino: 0.1922\n",
      "Época 39/100 - Loss treino: 0.1875\n",
      "Época 40/100 - Loss treino: 0.1829\n",
      "Época 41/100 - Loss treino: 0.1785\n",
      "Época 42/100 - Loss treino: 0.1743\n",
      "Época 43/100 - Loss treino: 0.1702\n",
      "Época 44/100 - Loss treino: 0.1663\n",
      "Época 45/100 - Loss treino: 0.1625\n",
      "Época 46/100 - Loss treino: 0.1588\n",
      "Época 47/100 - Loss treino: 0.1553\n",
      "Época 48/100 - Loss treino: 0.1520\n",
      "Época 49/100 - Loss treino: 0.1487\n",
      "Época 50/100 - Loss treino: 0.1456\n",
      "Época 51/100 - Loss treino: 0.1425\n",
      "Época 52/100 - Loss treino: 0.1396\n",
      "Época 53/100 - Loss treino: 0.1367\n",
      "Época 54/100 - Loss treino: 0.1339\n",
      "Época 55/100 - Loss treino: 0.1312\n",
      "Época 56/100 - Loss treino: 0.1287\n",
      "Época 57/100 - Loss treino: 0.1262\n",
      "Época 58/100 - Loss treino: 0.1238\n",
      "Época 59/100 - Loss treino: 0.1215\n",
      "Época 60/100 - Loss treino: 0.1193\n",
      "Época 61/100 - Loss treino: 0.1171\n",
      "Época 62/100 - Loss treino: 0.1150\n",
      "Época 63/100 - Loss treino: 0.1130\n",
      "Época 64/100 - Loss treino: 0.1110\n",
      "Época 65/100 - Loss treino: 0.1091\n",
      "Época 66/100 - Loss treino: 0.1073\n",
      "Época 67/100 - Loss treino: 0.1055\n",
      "Época 68/100 - Loss treino: 0.1037\n",
      "Época 69/100 - Loss treino: 0.1019\n",
      "Época 70/100 - Loss treino: 0.1002\n",
      "Época 71/100 - Loss treino: 0.0986\n",
      "Época 72/100 - Loss treino: 0.0970\n",
      "Época 73/100 - Loss treino: 0.0955\n",
      "Época 74/100 - Loss treino: 0.0940\n",
      "Época 75/100 - Loss treino: 0.0926\n",
      "Época 76/100 - Loss treino: 0.0912\n",
      "Época 77/100 - Loss treino: 0.0898\n",
      "Época 78/100 - Loss treino: 0.0884\n",
      "Época 79/100 - Loss treino: 0.0871\n",
      "Época 80/100 - Loss treino: 0.0859\n",
      "Época 81/100 - Loss treino: 0.0846\n",
      "Época 82/100 - Loss treino: 0.0834\n",
      "Época 83/100 - Loss treino: 0.0823\n",
      "Época 84/100 - Loss treino: 0.0811\n",
      "Época 85/100 - Loss treino: 0.0800\n",
      "Época 86/100 - Loss treino: 0.0788\n",
      "Época 87/100 - Loss treino: 0.0778\n",
      "Época 88/100 - Loss treino: 0.0767\n",
      "Época 89/100 - Loss treino: 0.0757\n",
      "Época 90/100 - Loss treino: 0.0747\n",
      "Época 91/100 - Loss treino: 0.0737\n",
      "Época 92/100 - Loss treino: 0.0728\n",
      "Época 93/100 - Loss treino: 0.0718\n",
      "Época 94/100 - Loss treino: 0.0709\n",
      "Época 95/100 - Loss treino: 0.0700\n",
      "Época 96/100 - Loss treino: 0.0691\n",
      "Época 97/100 - Loss treino: 0.0683\n",
      "Época 98/100 - Loss treino: 0.0674\n",
      "Época 99/100 - Loss treino: 0.0666\n",
      "Época 100/100 - Loss treino: 0.0658\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = OSATSResNetGRU().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = compute_loss(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    print(f\"Época {epoch+1}/{num_epochs} - Loss treino: {avg_loss:.4f}\")\n",
    "\n",
    "# Guardar o modelo\n",
    "torch.save(model.state_dict(), \"../outputs/models/model_task2_resnet_gru.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision Transformer (ViT) + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSATSViT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        vit = models.vit_b_16(pretrained=True)\n",
    "        vit.heads = nn.Identity()  # remover a cabeça original\n",
    "        self.backbone = vit  # saída: [B*T, 768]\n",
    "\n",
    "        self.shared = nn.Linear(768, 128)\n",
    "        self.heads = nn.ModuleList([nn.Linear(128, 5) for _ in range(8)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)             # [B*T, 3, 224, 224]\n",
    "        features = self.backbone(x)            # [B*T, 768]\n",
    "        features = features.view(B, T, -1)     # [B, T, 768]\n",
    "        pooled = features.mean(dim=1)          # média temporal → [B, 768]\n",
    "\n",
    "        shared = F.relu(self.shared(pooled))   # [B, 128]\n",
    "        return torch.stack([head(shared) for head in self.heads], dim=1)  # [B, 8, 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(preds, targets):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for i in range(preds.size(1)):  # 8 cabeças\n",
    "        total_loss += loss_fn(preds[:, i], targets[:, i])\n",
    "    \n",
    "    return total_loss / preds.size(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/miniconda3/envs/ap/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/luis/miniconda3/envs/ap/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1/100 - Loss treino: 1.5967\n",
      "Época 2/100 - Loss treino: 1.4559\n",
      "Época 3/100 - Loss treino: 1.4034\n",
      "Época 4/100 - Loss treino: 1.3681\n",
      "Época 5/100 - Loss treino: 1.3389\n",
      "Época 6/100 - Loss treino: 1.3237\n",
      "Época 7/100 - Loss treino: 1.3076\n",
      "Época 8/100 - Loss treino: 1.3019\n",
      "Época 9/100 - Loss treino: 1.3003\n",
      "Época 10/100 - Loss treino: 1.2948\n",
      "Época 11/100 - Loss treino: 1.2910\n",
      "Época 12/100 - Loss treino: 1.2892\n",
      "Época 13/100 - Loss treino: 1.2845\n",
      "Época 14/100 - Loss treino: 1.2943\n",
      "Época 15/100 - Loss treino: 1.2797\n",
      "Época 16/100 - Loss treino: 1.2858\n",
      "Época 17/100 - Loss treino: 1.2790\n",
      "Época 18/100 - Loss treino: 1.2678\n",
      "Época 19/100 - Loss treino: 1.2639\n",
      "Época 20/100 - Loss treino: 1.2576\n",
      "Época 21/100 - Loss treino: 1.2662\n",
      "Época 22/100 - Loss treino: 1.2545\n",
      "Época 23/100 - Loss treino: 1.3136\n",
      "Época 24/100 - Loss treino: 1.2715\n",
      "Época 25/100 - Loss treino: 1.2908\n",
      "Época 26/100 - Loss treino: 1.2722\n",
      "Época 27/100 - Loss treino: 1.2568\n",
      "Época 28/100 - Loss treino: 1.2614\n",
      "Época 29/100 - Loss treino: 1.2539\n",
      "Época 30/100 - Loss treino: 1.2600\n",
      "Época 31/100 - Loss treino: 1.2367\n",
      "Época 32/100 - Loss treino: 1.2387\n",
      "Época 33/100 - Loss treino: 1.2341\n",
      "Época 34/100 - Loss treino: 1.2094\n",
      "Época 35/100 - Loss treino: 1.1950\n",
      "Época 36/100 - Loss treino: 1.1892\n",
      "Época 37/100 - Loss treino: 1.2271\n",
      "Época 38/100 - Loss treino: 1.1870\n",
      "Época 39/100 - Loss treino: 1.1975\n",
      "Época 40/100 - Loss treino: 1.1959\n",
      "Época 41/100 - Loss treino: 1.1738\n",
      "Época 42/100 - Loss treino: 1.1484\n",
      "Época 43/100 - Loss treino: 1.1725\n",
      "Época 44/100 - Loss treino: 1.2137\n",
      "Época 45/100 - Loss treino: 1.2019\n",
      "Época 46/100 - Loss treino: 1.1285\n",
      "Época 47/100 - Loss treino: 1.1321\n",
      "Época 48/100 - Loss treino: 1.1056\n",
      "Época 49/100 - Loss treino: 1.0987\n",
      "Época 50/100 - Loss treino: 1.0814\n",
      "Época 51/100 - Loss treino: 1.0469\n",
      "Época 52/100 - Loss treino: 1.1015\n",
      "Época 53/100 - Loss treino: 1.2286\n",
      "Época 54/100 - Loss treino: 1.1919\n",
      "Época 55/100 - Loss treino: 1.2176\n",
      "Época 56/100 - Loss treino: 1.2568\n",
      "Época 57/100 - Loss treino: 1.1788\n",
      "Época 58/100 - Loss treino: 1.1370\n",
      "Época 59/100 - Loss treino: 1.1318\n",
      "Época 60/100 - Loss treino: 1.0307\n",
      "Época 61/100 - Loss treino: 1.0516\n",
      "Época 62/100 - Loss treino: 1.1155\n",
      "Época 63/100 - Loss treino: 1.0628\n",
      "Época 64/100 - Loss treino: 1.0246\n",
      "Época 65/100 - Loss treino: 1.0081\n",
      "Época 66/100 - Loss treino: 1.0747\n",
      "Época 67/100 - Loss treino: 1.1463\n",
      "Época 68/100 - Loss treino: 1.0501\n",
      "Época 69/100 - Loss treino: 1.0632\n",
      "Época 70/100 - Loss treino: 1.0917\n",
      "Época 71/100 - Loss treino: 1.0648\n",
      "Época 72/100 - Loss treino: 1.0553\n",
      "Época 73/100 - Loss treino: 1.0308\n",
      "Época 74/100 - Loss treino: 1.0380\n",
      "Época 75/100 - Loss treino: 1.1624\n",
      "Época 76/100 - Loss treino: 1.1330\n",
      "Época 77/100 - Loss treino: 1.0500\n",
      "Época 78/100 - Loss treino: 1.1448\n",
      "Época 79/100 - Loss treino: 1.3374\n",
      "Época 80/100 - Loss treino: 1.2535\n",
      "Época 81/100 - Loss treino: 1.2335\n",
      "Época 82/100 - Loss treino: 1.2063\n",
      "Época 83/100 - Loss treino: 1.1536\n",
      "Época 84/100 - Loss treino: 1.1174\n",
      "Época 85/100 - Loss treino: 1.0762\n",
      "Época 86/100 - Loss treino: 1.0590\n",
      "Época 87/100 - Loss treino: 1.1566\n",
      "Época 88/100 - Loss treino: 1.1040\n",
      "Época 89/100 - Loss treino: 1.1269\n",
      "Época 90/100 - Loss treino: 1.1269\n",
      "Época 91/100 - Loss treino: 1.0523\n",
      "Época 92/100 - Loss treino: 0.9879\n",
      "Época 93/100 - Loss treino: 0.9705\n",
      "Época 94/100 - Loss treino: 0.9447\n",
      "Época 95/100 - Loss treino: 0.9297\n",
      "Época 96/100 - Loss treino: 0.9188\n",
      "Época 97/100 - Loss treino: 0.9109\n",
      "Época 98/100 - Loss treino: 0.9032\n",
      "Época 99/100 - Loss treino: 0.9064\n",
      "Época 100/100 - Loss treino: 0.9105\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = OSATSViT().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = compute_loss(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    print(f\"Época {epoch+1}/{num_epochs} - Loss treino: {avg_loss:.4f}\")\n",
    "\n",
    "# Guardar o modelo\n",
    "torch.save(model.state_dict(), \"../outputs/models/model_task2_vit.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model_multihead(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_items = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)  # [B, 8, 5]\n",
    "            loss = criterion(outputs.view(-1, 5), targets.view(-1))\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            preds = outputs.argmax(dim=2)  # [B, 8]\n",
    "            total_correct += (preds == targets).sum().item()\n",
    "            total_items += targets.numel()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    avg_acc = total_correct / total_items\n",
    "    return avg_loss, avg_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/miniconda3/envs/ap/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model1 = CNNModel_1().to(device)\n",
    "model1.load_state_dict(torch.load(\"../outputs/models/model_task2_cnn1.pt\"))\n",
    "\n",
    "model2 = CNNModel_2().to(device)\n",
    "model2.load_state_dict(torch.load(\"../outputs/models/model_task2_cnn2.pt\"))\n",
    "\n",
    "model3 = CNNModel_3().to(device)\n",
    "model3.load_state_dict(torch.load(\"../outputs/models/model_task2_cnn3.pt\"))\n",
    "\n",
    "model4 = CNNModel_4().to(device)\n",
    "model4.load_state_dict(torch.load(\"../outputs/models/model_task2_cnn4.pt\"))\n",
    "\n",
    "model5 = OSATSResNet().to(device)\n",
    "model5.load_state_dict(torch.load(\"../outputs/models/model_task2_resnet.pt\"))\n",
    "\n",
    "model6 = OSATSResNetGRU().to(device)\n",
    "model6.load_state_dict(torch.load(\"../outputs/models/model_task2_resnet_gru.pt\"))\n",
    "\n",
    "model7 = OSATSViT().to(device)\n",
    "model7.load_state_dict(torch.load(\"../outputs/models/model_task2_vit.pt\"))\n",
    "\n",
    "models = {\n",
    "    \"CNNModel_1\": model1,\n",
    "    \"CNNModel_2\": model2,\n",
    "    \"CNNModel_3\": model3,\n",
    "    \"CNNModel_4\": model4,\n",
    "    \"ResNet + MLP\": model5,\n",
    "    \"ResNet + GRU\": model6,\n",
    "    \"ViT + MLP\": model7\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model_multihead(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)  # Esperado: [B, 8, 5]\n",
    "            B, N, C = outputs.shape  # B=batch, N=critérios, C=classes\n",
    "            outputs = outputs.view(B * N, C)\n",
    "            targets = targets.view(B * N)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "val_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    val_loss, val_acc = validate_model_multihead(model, val_loader, criterion)\n",
    "    val_results[name] = val_acc\n",
    "    print(f\"{name} - Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = max(val_results, key=val_results.get)\n",
    "best_model = models[best_model_name]\n",
    "print(f\"Melhor modelo: {best_model_name} com accuracy {val_results[best_model_name]:.4f}\")\n",
    "\n",
    "test_loss, test_acc = validate_model_multihead(best_model, test_loader, criterion)\n",
    "print(f\"Acurácia no Teste: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "osats_cols = [col for col in df.columns if col.startswith(\"OSATS_\")]\n",
    "\n",
    "best_model.eval()\n",
    "all_true, all_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = best_model(inputs)\n",
    "        preds = outputs.argmax(dim=2)\n",
    "\n",
    "        all_true.append(targets.cpu())\n",
    "        all_pred.append(preds.cpu())\n",
    "\n",
    "true = torch.cat(all_true)\n",
    "pred = torch.cat(all_pred)\n",
    "\n",
    "for i, col in enumerate(osats_cols):\n",
    "    cm = confusion_matrix(true[:, i], pred[:, i])\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"Matriz de Confusão - {col}\")\n",
    "    plt.xlabel(\"Predito\")\n",
    "    plt.ylabel(\"Verdadeiro\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
